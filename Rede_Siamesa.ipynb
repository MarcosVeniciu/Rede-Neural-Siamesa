{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcosVeniciu/Rede-Neural-Siamesa/blob/main/Rede_Siamesa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "import zipfile as zf\n",
        "import numpy as np\n",
        "import shutil\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "size = 96"
      ],
      "metadata": {
        "id": "vmK5covsUhNj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "LQKRgOTUUQJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções"
      ],
      "metadata": {
        "id": "0Ns0ULKYVHz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(dataset):\n",
        "  \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n",
        "  for anchor, positive, negative in dataset.take(1):\n",
        "    def show(ax, image):\n",
        "        ax.imshow(image, cmap=\"gray\")\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    fig = plt.figure(figsize=(9, 9))\n",
        "\n",
        "    axs = fig.subplots(3, 3)\n",
        "    for i in range(3):\n",
        "        show(axs[i, 0], anchor[0])\n",
        "        show(axs[i, 1], positive[0])\n",
        "        show(axs[i, 2], negative[0])"
      ],
      "metadata": {
        "id": "2f2PivNBW8JA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mnist"
      ],
      "metadata": {
        "id": "vBWFDxrZUTGt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Eg4t8X-xS_k0"
      },
      "outputs": [],
      "source": [
        "def descompactar_dataset(local):\n",
        "  shutil.rmtree(\"Dataset\", ignore_errors=True)\n",
        "  local_destino = \"Dataset\"\n",
        "  os.mkdir(local_destino) # Cria a pasta para salvar as imagens\n",
        "  z = zf.ZipFile((local + \".zip\"), 'r')\n",
        "  z.extractall(local_destino)\n",
        "  z.close()\n",
        "\n",
        "\n",
        "def process_diretorio(local_img):\n",
        "  img = cv2.imread(local_img, 0)\n",
        "  img = np.array([img]) \n",
        "  img = img.reshape(96, 96, 1)\n",
        "  img = img/255\n",
        "  return img\n",
        "\n",
        "\n",
        "def dataset_diretorio(quantidade_imagens = 20000): \n",
        "  nb_classes = 10\n",
        "  local_base = \"/content/Dataset/treino/\"\n",
        "  triplets=[np.zeros((quantidade_imagens, 96, 96, 1)) for i in range(3)]\n",
        "\n",
        "  for i in range(quantidade_imagens):\n",
        "    if i % 1000 == 0:\n",
        "      print(str(i) + \" imagens foram adicionadas.\")\n",
        "\n",
        "    anchor_class = np.random.randint(0, nb_classes) # Sorteia o indice de uma das classes de 0 a 9\n",
        "    local_ancora = local_base + str(anchor_class)\n",
        "    local_positiva = local_ancora \n",
        "    lista_imagens = os.listdir(local_ancora)\n",
        "    nb_sample_available_for_class_AP = len(lista_imagens) # verifica a quantidade de imagens na classe de indice anchor_class\n",
        " \n",
        "    # imagem ancora\n",
        "    idx_A = np.random.randint(0, nb_sample_available_for_class_AP)\n",
        "    local_ancora = local_ancora + \"/\" + lista_imagens[idx_A]\n",
        "\n",
        "    # imagem positiva\n",
        "    idx_P = np.random.randint(0, nb_sample_available_for_class_AP)\n",
        "    local_positiva =  local_positiva + \"/\" +  lista_imagens[idx_P]\n",
        "\n",
        "    # Imagem negativa\n",
        "    negative_class = (anchor_class + np.random.randint(1,nb_classes)) % nb_classes # seleciona uma outra classe para ser a negativa\n",
        "    local_negativa = local_base + str(negative_class)\n",
        "    lista_imagens = os.listdir(local_negativa)\n",
        "    nb_sample_available_for_class_N = len(lista_imagens)\n",
        "    idx_N = np.random.randint(0, nb_sample_available_for_class_N)\n",
        "    local_negativa = local_negativa + \"/\" +  lista_imagens[idx_N]\n",
        "\n",
        "    triplets[0][i,:,:,:] = process_diretorio(local_ancora)\n",
        "    triplets[1][i,:,:,:] = process_diretorio(local_positiva)\n",
        "    triplets[2][i,:,:,:] = process_diretorio(local_negativa)\n",
        " \n",
        "  dataset = tf.data.Dataset.zip((\n",
        "  tf.data.Dataset.from_tensor_slices(triplets[0]), # anchor_dataset\n",
        "  tf.data.Dataset.from_tensor_slices(triplets[1]), # positive_dataset\n",
        "  tf.data.Dataset.from_tensor_slices(triplets[2])))# negative_dataset\n",
        "  return dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gerar DataSet"
      ],
      "metadata": {
        "id": "Zs4mbb6KVKnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_rqFgedGBw_F",
        "outputId": "dcaa35bd-ffb7-48dd-9f30-66da746bccf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#descompactar_dataset(\"/content/drive/MyDrive/Codedepot/DataSets/mnist\")\n",
        "\n",
        "dataset = dataset_diretorio(quantidade_imagens = 10000)\n",
        "dataset = dataset.shuffle(buffer_size=1024)\n",
        "#visualize(dataset)\n",
        "\n",
        "train_ds = dataset.take(round(len(dataset) * 0.8))\n",
        "val_ds = dataset.skip(round(len(dataset) * 0.8))\n",
        "\n",
        "print(\"Total de imagens: \" + str(len(dataset)))\n",
        "print(\"   Treinamento: \" + str(len(train_ds)))\n",
        "print(\"   Validação: \" + str(len(val_ds)))\n",
        "\n",
        "\n",
        "train_ds = train_ds.batch(32, drop_remainder=False)\n",
        "val_ds = val_ds.batch(32, drop_remainder=False)\n",
        "train_ds = train_ds.prefetch(8)\n",
        "val_ds = val_ds.prefetch(8)"
      ],
      "metadata": {
        "id": "JvS_Q9wEVNEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d798406-d393-405b-ebab-229811b036cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 imagens foram adicionadas.\n",
            "1000 imagens foram adicionadas.\n",
            "2000 imagens foram adicionadas.\n",
            "3000 imagens foram adicionadas.\n",
            "4000 imagens foram adicionadas.\n",
            "5000 imagens foram adicionadas.\n",
            "6000 imagens foram adicionadas.\n",
            "7000 imagens foram adicionadas.\n",
            "8000 imagens foram adicionadas.\n",
            "9000 imagens foram adicionadas.\n",
            "Total de imagens: 10000\n",
            "   Treinamento: 8000\n",
            "   Validação: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "GGJWnE3jXTAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Artigo: https://arxiv.org/pdf/1801.04381.pdf\n",
        "# Codigo keras: https://github.com/keras-team/keras-applications/blob/06fbeb0f16e1304f239b2296578d1c50b15a983a/keras_applications/mobilenet_v2.py#L425\n",
        "# Uma explicação sobre a arquitetura: https://machinethink.net/blog/mobilenet-v2/\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None): # A mesma coisa do keras\n",
        "  if min_value is None:\n",
        "    min_value = divisor\n",
        "  new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "  # Make sure that round down does not go down by more than 10%.\n",
        "  if new_v < 0.9 * v:\n",
        "    new_v += divisor\n",
        "  return new_v\n",
        "\n",
        "\n",
        "def bottleneck(inputs, expansion, stride, filters, alpha): # expansion = t, stride = s, filters = c\n",
        "  x = inputs\n",
        "\n",
        "  channel_axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
        "  in_channels = keras.backend.int_shape(inputs)[channel_axis]\n",
        "  expanded_channel_axis = in_channels * expansion\n",
        "  \n",
        "  pointwise_conv_filters = int(filters * alpha)\n",
        "  pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
        "\n",
        "  # Expand: 1x1 conv2d , ReLU6 \n",
        "  # Serve para multiplicar o numero de filtros da entrada por um fator de expansion\n",
        "  x = layers.Conv2D(expanded_channel_axis, 1, padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU(6.)(x)\n",
        "\n",
        "  # Depthwise: 3x3 dwise s=s, ReLU6 (s significa stride) \n",
        "  x = layers.DepthwiseConv2D(kernel_size=3, strides=stride, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU(6.)(x)\n",
        "\n",
        "  # Project: linear 1x1 conv2d, alpha = 1\n",
        "  # serve para reverter o processo de expanção\n",
        "  x = layers.Conv2D(pointwise_filters, 1, padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "\n",
        "  # A conexão residual é usada apenas quando o número de canais que entram no bloco é igual ao número que saem dele e o stride for igual a 1\n",
        "  if ((in_channels == pointwise_filters) and (stride == 1)): \n",
        "   x = layers.Add()([inputs, x])\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "def model(input_shape, dropout = 0.5, alpha = 1, dropout_seed = 42):\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "  scale_layer = layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
        "  x = scale_layer(inputs)\n",
        "\n",
        "  x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU(6.)(x) # Pode dar problema nesso troço de relu\n",
        "\n",
        "  # bottleneck 1\n",
        "  x = bottleneck(inputs= x , expansion= 1, stride= 1, filters= 16, alpha = alpha) # expansion = t, stride = s, filters = c\n",
        "\n",
        "  # bottleneck 2 e 3\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 2, filters= 24, alpha = alpha)\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 24, alpha = alpha)\n",
        "  \n",
        "  # bottleneck 4 \n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 2, filters= 32, alpha = alpha)\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 32, alpha = alpha)\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 32, alpha = alpha)\n",
        "\n",
        "  # bottleneck 7, 8, 9 e 10\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 2, filters= 64, alpha = alpha)\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 64, alpha = alpha)\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 64, alpha = alpha)\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 64, alpha = alpha)\n",
        "\n",
        "  # bottleneck 11, 12 e 13\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 96, alpha = alpha)\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 96, alpha = alpha)\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 96, alpha = alpha)\n",
        " \n",
        "  # bottleneck 14, 15 e 16\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 2, filters= 160, alpha = alpha)\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 160, alpha = alpha)\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 160, alpha = alpha)\n",
        "\n",
        "  # bottleneck 17\n",
        "  x = bottleneck(inputs= x , expansion= 6, stride= 1, filters= 320, alpha = alpha)\n",
        "\n",
        "\n",
        "  x = layers.Conv2D(1280, 1, strides=1, padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU(6.)(x)\n",
        "\n",
        "  x = layers.GlobalAveragePooling2D()(x)  \n",
        "  outputs = layers.Dense(128)(x)\n",
        "  \n",
        "  return keras.Model(inputs, outputs, name=\"Embedding_MobileNetV2\")"
      ],
      "metadata": {
        "id": "ZjkTQmuHXT5m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://keras.io/examples/vision/siamese_network/\n",
        "# https://keras.io/examples/vision/siamese_contrastive/\n",
        "# https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d\n",
        "#tf.keras.backend.set_image_data_format('channels_first')\n",
        "\n",
        "input_shape = (96,96, 1)\n",
        "\n",
        "\n",
        "class DistanceLayer(keras.layers.Layer):\n",
        "  \"\"\"\n",
        "  This layer is responsible for computing the distance between the anchor\n",
        "  embedding and the positive embedding, and the anchor embedding and the\n",
        "  negative embedding.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "  def call(self, anchor, positive, negative):\n",
        "    ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
        "    an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
        "    return (ap_distance, an_distance)\n",
        "\n",
        "\n",
        "\n",
        "embedding_model = model(input_shape = input_shape)\n",
        "embedding_model.summary()\n",
        "\n",
        "def Siamese_Network():\n",
        "  anchor_input = keras.layers.Input(name=\"anchor\", shape= input_shape)\n",
        "  positive_input = keras.layers.Input(name=\"positive\", shape=input_shape)\n",
        "  negative_input = keras.layers.Input(name=\"negative\", shape=input_shape)\n",
        "\n",
        "  distances = DistanceLayer()(\n",
        "      embedding_model(anchor_input),\n",
        "      embedding_model(positive_input),\n",
        "      embedding_model(negative_input),\n",
        "    )\n",
        "\n",
        "  return keras.Model(inputs=[anchor_input, positive_input, negative_input], outputs=distances, name='Siamese_Network')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2USxsR8ZeL3",
        "outputId": "9ec4e595-f8bd-43ae-8007-2124f08076f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Embedding_MobileNetV2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 96, 96, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 96, 96, 1)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 48, 48, 32)   320         ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 48, 48, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 48, 48, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 48, 48, 32)   1056        ['re_lu[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 48, 48, 32)  128         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 48, 48, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 48, 48, 32)  320         ['re_lu_1[0][0]']                \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 48, 48, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 48, 48, 32)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 48, 48, 16)   528         ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 48, 48, 16)  64          ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 48, 48, 96)   1632        ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 48, 48, 96)  384         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 48, 48, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 24, 24, 96)  960         ['re_lu_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 24, 24, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 24, 24, 96)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 24, 24, 24)   2328        ['re_lu_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 24, 24, 24)  96          ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 24, 24, 144)  3600        ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 24, 24, 144)  576        ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 24, 24, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 24, 24, 144)  1440       ['re_lu_5[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 24, 24, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 24, 24, 144)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 24, 24, 24)   3480        ['re_lu_6[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 24, 24, 24)  96          ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 24, 24, 24)   0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 24, 24, 144)  3600        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 24, 24, 144)  576        ['conv2d_7[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 24, 24, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 12, 12, 144)  1440       ['re_lu_7[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 12, 12, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 12, 12, 144)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 12, 12, 32)   4640        ['re_lu_8[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 12, 12, 32)  128         ['conv2d_8[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 12, 12, 192)  6336        ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 12, 12, 192)  768        ['conv2d_9[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 12, 12, 192)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 12, 12, 192)  1920       ['re_lu_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 12, 12, 192)  768        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 12, 12, 192)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 12, 12, 32)   6176        ['re_lu_10[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 12, 12, 32)  128         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 12, 12, 32)   0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 12, 12, 192)  6336        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 12, 12, 192)  768        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 12, 12, 192)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 12, 12, 192)  1920       ['re_lu_11[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 12, 12, 192)  768        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 12, 12, 192)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 12, 12, 32)   6176        ['re_lu_12[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 12, 12, 32)  128         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 12, 12, 32)   0           ['add_1[0][0]',                  \n",
            "                                                                  'batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 12, 12, 192)  6336        ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 12, 12, 192)  768        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 12, 12, 192)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 6, 6, 192)   1920        ['re_lu_13[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 6, 6, 192)   768         ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 6, 6, 192)    0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 6, 6, 64)     12352       ['re_lu_14[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 6, 6, 64)    256         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 6, 6, 384)    24960       ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 6, 6, 384)   1536        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 6, 6, 384)    0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 6, 6, 384)   3840        ['re_lu_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 6, 6, 384)   1536        ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 6, 6, 384)    0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 6, 6, 64)     24640       ['re_lu_16[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 6, 6, 64)    256         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 6, 6, 64)     0           ['batch_normalization_21[0][0]', \n",
            "                                                                  'batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 6, 6, 384)    24960       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 6, 6, 384)   1536        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 6, 6, 384)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 6, 6, 384)   3840        ['re_lu_17[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 6, 6, 384)   1536        ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 6, 6, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 6, 6, 64)     24640       ['re_lu_18[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 6, 6, 64)    256         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 6, 6, 64)     0           ['add_3[0][0]',                  \n",
            "                                                                  'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 6, 6, 384)    24960       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 6, 6, 384)   1536        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 6, 6, 384)    0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 6, 6, 384)   3840        ['re_lu_19[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 6, 6, 384)   1536        ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 6, 6, 384)    0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 6, 6, 64)     24640       ['re_lu_20[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 6, 6, 64)    256         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 6, 6, 64)     0           ['add_4[0][0]',                  \n",
            "                                                                  'batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 6, 6, 384)    24960       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 6, 6, 384)   1536        ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 6, 6, 384)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 6, 6, 384)   3840        ['re_lu_21[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 6, 6, 384)   1536        ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 6, 6, 384)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 6, 6, 96)     36960       ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 6, 6, 96)    384         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 6, 6, 576)    55872       ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 6, 6, 576)   2304        ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)                (None, 6, 6, 576)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 6, 6, 576)   5760        ['re_lu_23[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 6, 6, 576)   2304        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)                (None, 6, 6, 576)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 6, 6, 96)     55392       ['re_lu_24[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 6, 6, 96)    384         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 6, 6, 96)     0           ['batch_normalization_33[0][0]', \n",
            "                                                                  'batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 6, 6, 576)    55872       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 6, 6, 576)   2304        ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)                (None, 6, 6, 576)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 6, 6, 576)   5760        ['re_lu_25[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 6, 6, 576)   2304        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)                (None, 6, 6, 576)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 6, 6, 96)     55392       ['re_lu_26[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 6, 6, 96)    384         ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 6, 6, 96)     0           ['add_6[0][0]',                  \n",
            "                                                                  'batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 6, 6, 576)    55872       ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 6, 6, 576)   2304        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_27 (ReLU)                (None, 6, 6, 576)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 3, 3, 576)   5760        ['re_lu_27[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 3, 3, 576)   2304        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)                (None, 3, 3, 576)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 3, 3, 160)    92320       ['re_lu_28[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 3, 3, 160)   640         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 3, 3, 960)    154560      ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 3, 3, 960)   3840        ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)                (None, 3, 3, 960)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 3, 3, 960)   9600        ['re_lu_29[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 3, 3, 960)   3840        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)                (None, 3, 3, 960)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 3, 3, 160)    153760      ['re_lu_30[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 3, 3, 160)   640         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 3, 3, 160)    0           ['batch_normalization_42[0][0]', \n",
            "                                                                  'batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 3, 3, 960)    154560      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 3, 3, 960)   3840        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)                (None, 3, 3, 960)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 3, 3, 960)   9600        ['re_lu_31[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 3, 3, 960)   3840        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_32 (ReLU)                (None, 3, 3, 960)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 3, 3, 160)    153760      ['re_lu_32[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 3, 3, 160)   640         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 3, 3, 160)    0           ['add_8[0][0]',                  \n",
            "                                                                  'batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 3, 3, 960)    154560      ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 3, 3, 960)   3840        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_33 (ReLU)                (None, 3, 3, 960)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 3, 3, 960)   9600        ['re_lu_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 3, 3, 960)   3840        ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_34 (ReLU)                (None, 3, 3, 960)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 3, 3, 320)    307520      ['re_lu_34[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 3, 3, 320)   1280        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 3, 3, 1280)   410880      ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 3, 3, 1280)  5120        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_35 (ReLU)                (None, 3, 3, 1280)   0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1280)        0           ['re_lu_35[0][0]']               \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          163968      ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,439,616\n",
            "Trainable params: 2,405,440\n",
            "Non-trainable params: 34,176\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseModel(keras.models.Model):\n",
        "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
        "\n",
        "    Computes the triplet loss using the three embeddings produced by the\n",
        "    Siamese Network.\n",
        "\n",
        "    The triplet loss is defined as:\n",
        "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, siamese_network, margin=0.3):\n",
        "        super().__init__()\n",
        "        self.siamese_network = siamese_network\n",
        "        self.margin = margin\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.siamese_network(inputs)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # GradientTape is a context manager that records every operation that\n",
        "        # you do inside. We are using it here to compute the loss so we can get\n",
        "        # the gradients and apply them using the optimizer specified in\n",
        "        # `compile()`.\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self._compute_loss(data)\n",
        "\n",
        "        # Storing the gradients of the loss function with respect to the\n",
        "        # weights/parameters.\n",
        "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
        "\n",
        "        # Applying the gradients on the model using the specified optimizer\n",
        "        self.optimizer.apply_gradients(\n",
        "            zip(gradients, self.siamese_network.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Let's update and return the training loss metric.\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        loss = self._compute_loss(data)\n",
        "\n",
        "        # Let's update and return the loss metric.\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def _compute_loss(self, data):\n",
        "        # The output of the network is a tuple containing the distances\n",
        "        # between the anchor and the positive example, and the anchor and\n",
        "        # the negative example.\n",
        "        ap_distance, an_distance = self.siamese_network(data)\n",
        "\n",
        "        # Computing the Triplet Loss by subtracting both distances and\n",
        "        # making sure we don't get a negative value.\n",
        "        loss = ap_distance - an_distance\n",
        "        loss = tf.maximum(loss + self.margin, 0.0)\n",
        "        return loss\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We need to list our metrics here so the `reset_states()` can be\n",
        "        # called automatically.\n",
        "        return [self.loss_tracker]"
      ],
      "metadata": {
        "id": "1sEtgf1BaNju"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "WClf_ZErcm2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=8, monitor=\"val_loss\", restore_best_weights=True),\n",
        "  ]"
      ],
      "metadata": {
        "id": "Uqnl8V7qcotM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model = SiameseModel(Siamese_Network())\n",
        "siamese_model.compile(optimizer=keras.optimizers.Adam(0.0001), weighted_metrics=[\"loss\"])"
      ],
      "metadata": {
        "id": "k2-oYM7wctZw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historico = siamese_model.fit(train_ds, epochs=20, callbacks=my_callbacks, validation_data = val_ds)\n",
        "embedding_model.save(\"embedding_model.h5\")"
      ],
      "metadata": {
        "id": "VV8KVU_YdHGQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "462ac818-83bb-4ef0-96ad-dd8eec2f53d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 98s 159ms/step - loss: 0.3000 - val_loss: 0.3000\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.3000 - val_loss: 0.3000\n",
            "Epoch 3/20\n",
            "  1/250 [..............................] - ETA: 48s - loss: 0.3000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-83086fa52a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistorico\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def diferenca(historico):\n",
        "  accuracy = historico.history['loss'] \n",
        "  val_accuracy = historico.history['val_loss']\n",
        "  vetor_diferenca = []\n",
        "  for i in range(len(accuracy)):\n",
        "    diferenca = abs(accuracy[i] - val_accuracy[i])\n",
        "    vetor_diferenca.append(diferenca)\n",
        "\n",
        "  return vetor_diferenca\n",
        "\n",
        "  \n",
        "def grafico(historico, nome): \n",
        "\n",
        "  plt.subplots(figsize=(25, 5)) \n",
        "  # Grafico 1: Loss\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.title( nome + ': Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Cross Entropy')\n",
        "  plt.grid()\n",
        "  plt.plot(historico.history['loss'], label='Train Loss ', color = 'blue')\n",
        "  plt.plot(historico.history['val_loss'], label='Val Loss ', color = 'red')\n",
        "  plt.legend()\n",
        "\n",
        "\n",
        "  # Grafico 3: Diferença de Loss\n",
        "  vetor_diferenca = diferenca(historico)\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.title(nome + \": Variação do Loss\")\n",
        "  plt.xlabel(\"Epocas\")\n",
        "  plt.ylabel(\"Diferença\")\n",
        "  plt.grid()\n",
        "  plt.plot(vetor_diferenca, color = 'red', label = 'Variação do Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  nome_save = os.path.join(\"/content\", nome + \".jpg\")\n",
        "  plt.savefig(nome_save, dpi=400,  transparent=False)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "grafico(historico, \"Rede Siamesa\")"
      ],
      "metadata": {
        "id": "GHhPSbOvdzcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste"
      ],
      "metadata": {
        "id": "DiFX1xZUagCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções"
      ],
      "metadata": {
        "id": "e9j7zvTTvfXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_origin, y_train_origin), (x_test_origin, y_test_origin) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "J1QsxJa1oTOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26214ec4-5be2-4ef7-ee7a-7a05d96173b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(x_test_origin):\n",
        "    \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n",
        "    print(\"Total de imagens: {0}  Resolução: {1}x{2}\".format(x_test_origin.shape[0], x_test_origin.shape[1], x_test_origin.shape[2]))\n",
        "    def show(ax, image):\n",
        "        ax.imshow(image, cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    fig = plt.figure(figsize=(9, 9))\n",
        "\n",
        "    axs = fig.subplots(3, 3)\n",
        "    for i in range(3):\n",
        "        show(axs[i, 0], x_test_origin[np.random.randint(0, 1000)])\n",
        "        show(axs[i, 1], x_test_origin[np.random.randint(0, 1000)])\n",
        "        show(axs[i, 2], x_test_origin[np.random.randint(0, 1000)])"
      ],
      "metadata": {
        "id": "Fp70tJqegdl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nome = [\"zero\", \"um\", \"dois\", \"tres\", \"quatro\", \"cinco\", \"seis\", \"sete\", \"oito\", \"nove\"]\n",
        "\n",
        "def array_to_imagem(image, novo_nome):\n",
        "  novo_nome = \"/content/imagens/\" + novo_nome + \".jpg\"\n",
        "  cv2.imwrite(novo_nome, image)\n",
        "\n",
        "def salvar_ancoras(x_test_origin, y_test_origin):\n",
        "  os.mkdir(\"imagens\")\n",
        "  \n",
        "\n",
        "  indice = 0\n",
        "  i = 0\n",
        "  while indice < 10:\n",
        "    if y_test_origin[i] == indice:\n",
        "      array_to_imagem(x_test_origin[i], nome[indice])\n",
        "      indice += 1\n",
        "    i+= 1"
      ],
      "metadata": {
        "id": "QRXcbFLscx0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ler_imagem(local):\n",
        "  return cv2.imread(local, 0)"
      ],
      "metadata": {
        "id": "N-RVQJqf1OXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_database(model):\n",
        "  database = {}\n",
        "  local = \"/content/imagens\"\n",
        "  for imagem in os.listdir(local):\n",
        "    local_imagem = os.path.join(local, imagem)\n",
        "    img = ler_imagem(local_imagem)\n",
        "    identity = os.path.splitext(os.path.basename(local_imagem))[0]\n",
        "    database[identity] = img_to_encoding(img, model)\n",
        "  \n",
        "  return database"
      ],
      "metadata": {
        "id": "YA2FBid_GzDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recognise_class(image, database, model):\n",
        "    encoding = img_to_encoding(image, model)\n",
        "    identity = None\n",
        "    min_dist = 100\n",
        "    for (name, db_enc) in database.items():\n",
        "        \n",
        "        dist = np.linalg.norm(db_enc - encoding)\n",
        "        #print('distance for %s is %s' %(name, dist))\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "    \n",
        "    if min_dist > 0.6:\n",
        "        return \"can't recognise.\"\n",
        "    else:\n",
        "        return str(identity)"
      ],
      "metadata": {
        "id": "iNOBlli0w9Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_to_encoding(img, model):\n",
        " # img = np.resize(image,(size,size))\n",
        "  img = np.array([img]) \n",
        "  img = img.reshape(img.shape[0], 1, size, size)\n",
        "\n",
        "  embedding = model.predict(img, verbose=0)\n",
        "  \n",
        "  return embedding"
      ],
      "metadata": {
        "id": "yEPUhahFxEkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metricas(saida):\n",
        "  certo = 0\n",
        "  errado = 0\n",
        "  incerto = 0\n",
        "  \n",
        "  for resposta in saida:\n",
        "    if resposta[1] == nome[resposta[0]]:\n",
        "      certo += 1\n",
        "    else:\n",
        "      if resposta[1] == \"can't recognise.\":\n",
        "        incerto += 1\n",
        "      else:\n",
        "        if resposta[1] != nome[resposta[0]]:\n",
        "          errado += 1\n",
        "  print()\n",
        "  print(\"Total de imagem: {0}    Certas: {1}   Erradas: {2}   Incertas: {3}\".format(len(saida), certo, errado, incerto))"
      ],
      "metadata": {
        "id": "u-3Xo4oqUHAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testes"
      ],
      "metadata": {
        "id": "p8Lj7oyPvj4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Permite visualizar algumas imagens do conjunto de teste\n",
        "visualize(x_test_origin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "hBghuIHbvq8E",
        "outputId": "d338bb5c-0e01-4470-bf86-2f5ab4c77deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imagens: 10000  Resolução: 28x28\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# salvar uma imagem de cada classe para ser a ancora\n",
        "salvar_ancoras(x_test_origin, y_test_origin)"
      ],
      "metadata": {
        "id": "0Q2KrYtawHVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para classificar um imagem como pertencente a uma das classe, o processo é dividido em 4 fasses: \\\n",
        "\n",
        "1 - uma imagem representando cada classe é codificada. \\\n",
        "\n",
        "2 - a imagem que sera classifica é codificada. \\\n",
        "\n",
        "3 - verifica a distancia da imagem codificada na fasse 2 com cada uma das imagens codificadas na fasse 1. \\\n",
        "\n",
        "4 - a imagem sera classificada de acordo com a menor distancia encontrada na fasse 3.\n"
      ],
      "metadata": {
        "id": "jtwzdkX_uFMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = tf.keras.models.load_model(\"/content/embedding_model.h5\")"
      ],
      "metadata": {
        "id": "GX_8g0g9y4no",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2be963-aaef-4545-e932-69326da71625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database = prepare_database(embedding_model)\n",
        "saida = []\n",
        "\n",
        "for i in range(15): # o maximo é 10000\n",
        "  classe = recognise_class(x_test_origin[i], database, embedding_model)\n",
        "  print(\"id {2}:: Classe Real: {0} >> Classe Prevista: {1}\".format(y_test_origin[i], classe, i))\n",
        "  saida.append([y_test_origin[i], classe])\n",
        "\n",
        "metricas(saida) "
      ],
      "metadata": {
        "id": "PBZHOZ98vGPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagens = cv2.imread(\"/content/temp.jpg\", 0)\n",
        "\n",
        "database = prepare_database(embedding_model)\n",
        "\n",
        "classe = recognise_class(imagens, database, embedding_model)\n",
        "print(classe)"
      ],
      "metadata": {
        "id": "aYo0dzIkuNQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verifica as imagem que deram errado\n",
        "cv2.imwrite(\"teste.jpg\",x_test_origin[7])"
      ],
      "metadata": {
        "id": "kfU0SIo0XY2x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}